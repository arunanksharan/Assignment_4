{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Assignment 4: **\n",
    "Write a code to extract the keywords from the document shared in the link http://bit.ly/epo_keyword_extraction_document, and upload the code in Github and also mention the keywords in order of their weightages in a Google doc or excel sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_read  = \"C:\\\\Users\\\\Admin\\\\Documents\\\\Heathens\\\\Data Science\\\\Internship\\\\A_4_KeywordsfromPDF.pdf\"\n",
    "\n",
    "# Creating pdf object\n",
    "with open(path_read, 'rb') as pdfFile:\n",
    "    pdf = PyPDF2.PdfFileReader(pdfFile) \n",
    "\n",
    "# Parsing across the document using number of pages\n",
    "    numberPages = pdf.getNumPages()\n",
    "# Initialising raw_text as blank string\n",
    "    raw_text = \"\"\n",
    "    for i in range(numberPages):\n",
    "        page = pdf.getPage(i)\n",
    "        raw_text += page.extractText()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test to check if raw_text has words because\n",
    "# if original pdf file is scanned, it cannot be read by PyPDF2\n",
    "\n",
    "if raw_text != \"\":\n",
    "    raw_text = raw_text\n",
    "else:\n",
    "    print(\"PDF appears to be a scanned file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2447"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning on raw_text to remove punctuations and frequently used stopwords\n",
    "\n",
    "# List of punctuations\n",
    "punctuations = [\"!\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"(\", \")\", \"-\", \"+\", \"_\", \"=\", \"==\",\n",
    "                \"[\", \"]\", \"{\", \"}\", \";\", \":\", ',', '.', \"<\", \">\", \"?\", \"/\", \"..\", \"...\", \n",
    "                \"``\", '\"\"', \"''\", \"--\", \"\\\\\", \"//\", \"*/\", \"/*\", \"/**\", \"`\", \"~\"]\n",
    "\n",
    "# List of stopwords\n",
    "stopwordList = stopwords.words('english')\n",
    "\n",
    "# raw_text is tokenised\n",
    "tokens = word_tokenize(raw_text.lower())\n",
    "\n",
    "# List of keywords created by excluding the punctuations and stopwords\n",
    "\n",
    "keywords = [word for word in tokens if not word in stopwordList and not word in str(punctuations)]\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating word frequency\n",
    "\n",
    "wordFrequency = nltk.Counter(keywords)\n",
    "wordMostCommon100 = wordFrequency.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of words appearing more than 5 times\n",
    "wordMoreThan5 = []\n",
    "\n",
    "for i in range(len(wordMostCommon100)):\n",
    "    if wordMostCommon100[i][1] > 5:\n",
    "        wordMoreThan5.append(wordMostCommon100[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of bigrams using tokenized text - tokens\n",
    "# Pointwise Mutual Information (PMI) as measure of association \n",
    "\n",
    "bigramMeasure = nltk.collocations.BigramAssocMeasures()\n",
    "bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(tokens)\n",
    "bigramFinder.apply_freq_filter(3)\n",
    "\n",
    "bigramWeightage = bigramFinder.score_ngrams(bigram_measures.pmi)\n",
    "top50Bigram = bigramFinder.nbest(bigram_measures.pmi, 50)\n",
    "top50BigramByWeightage = bigramFinder.score_ngrams(bigram_measures.pmi)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Analysis of co-occurrence of two words using Point Mutual Information (PMI) as metric for measure of association was performed. ** \n",
    "\n",
    "Good collocation pairs have high PMI as probability of co-occurrence is only slightly lower than probability of occurrence of each word.\n",
    "\n",
    "The top 50 bigram collocations in the given text are listed above as top50Bigram. Frequency filter is applied and bigrams occurring less than 3 times have been ignored.\n",
    "\n",
    "Measures are available to score collocations and score_ngrams is used here to compute the scores.\n",
    "\n",
    "Top 50 bigrams are selected.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramDataframe = pd.DataFrame(top50BigramByWeightage, columns=[\"Bigram\", \"Weightage\"])\n",
    "\n",
    "pathWriteExcel = \"C:\\\\Users\\\\Admin\\\\Documents\\\\Heathens\\\\Data Science\\\\Internship\\\\A_4_KeywordsfromPDF.xlsx\"\n",
    "write = pd.ExcelWriter(pathWriteExcel, engine='xlsxwriter')\n",
    "bigramDataframe.to_excel(write, index=False, sheet_name='KeywordsByWeightage')\n",
    "write.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The bigrams by their weightage are written into Excel file - A_4_KeywordsfromPDF.xlsx. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('import', 'java.applet.applet'),\n",
       " ('pointernull', 'pointernull'),\n",
       " ('graphics', 'g'),\n",
       " ('+', '34'),\n",
       " ('+', 'getparameter'),\n",
       " ('automatic', 'garbage'),\n",
       " ('garbage', 'collection'),\n",
       " ('garbage', 'collector'),\n",
       " ('runtime', 'system'),\n",
       " ('predefined', 'methods'),\n",
       " ('called', 'when'),\n",
       " ('www', 'browser'),\n",
       " ('<', 'param'),\n",
       " ('primitive', 'types'),\n",
       " ('else', 'return'),\n",
       " ('c++', 'style'),\n",
       " ('should', 'be'),\n",
       " ('string', 'literal'),\n",
       " ('basics©', '1996-2003'),\n",
       " ('basicsjava', 'basics'),\n",
       " ('by', 'contrast'),\n",
       " ('rights', 'reserved.java'),\n",
       " ('1996-2003', 'jguru.com'),\n",
       " ('j', '+'),\n",
       " ('reserved.java', 'basics'),\n",
       " ('extends', 'applet'),\n",
       " ('be', 'used'),\n",
       " ('public', 'void'),\n",
       " ('all', 'rights'),\n",
       " ('return', 'j'),\n",
       " ('such', 'as'),\n",
       " ('byte', 'code'),\n",
       " ('an', 'appletviewer'),\n",
       " ('allocate', 'memory'),\n",
       " ('passed', 'by'),\n",
       " ('when', 'you'),\n",
       " ('/*', 'allocate'),\n",
       " ('does', 'not'),\n",
       " ('``', 'ok'),\n",
       " ('``', 'quit'),\n",
       " ('do', 'not'),\n",
       " ('you', 'would'),\n",
       " ('ok', \"''\"),\n",
       " ('quit', \"''\"),\n",
       " ('those', 'in'),\n",
       " ('for', 'example'),\n",
       " ('language', 'has'),\n",
       " ('//', 'b.data'),\n",
       " ('this', 'method'),\n",
       " ('make', 'array')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('import', 'java.applet.applet'),\n",
       " ('pointernull', 'pointernull'),\n",
       " ('graphics', 'g'),\n",
       " ('+', '34'),\n",
       " ('+', 'getparameter'),\n",
       " ('automatic', 'garbage'),\n",
       " ('garbage', 'collection'),\n",
       " ('garbage', 'collector'),\n",
       " ('runtime', 'system'),\n",
       " ('predefined', 'methods'),\n",
       " ('called', 'when'),\n",
       " ('www', 'browser'),\n",
       " ('<', 'param'),\n",
       " ('primitive', 'types'),\n",
       " ('else', 'return'),\n",
       " ('c++', 'style'),\n",
       " ('should', 'be'),\n",
       " ('string', 'literal'),\n",
       " ('basics©', '1996-2003'),\n",
       " ('basicsjava', 'basics')]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50Bigram[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java', 71),\n",
       " ('new', 47),\n",
       " ('data', 42),\n",
       " ('button', 34),\n",
       " ('int', 29),\n",
       " ('code', 27),\n",
       " ('applet', 27),\n",
       " ('class', 26),\n",
       " ('b', 26),\n",
       " ('array', 24),\n",
       " ('1996-2003', 23),\n",
       " ('jguru.com', 23),\n",
       " ('rights', 23),\n",
       " ('basics', 23),\n",
       " ('string', 22),\n",
       " ('public', 21),\n",
       " ('c++', 21),\n",
       " ('object', 20),\n",
       " ('method', 19),\n",
       " ('example', 18),\n",
       " ('objects', 17),\n",
       " ('1', 17),\n",
       " ('5', 15),\n",
       " ('language', 14),\n",
       " ('3', 14),\n",
       " ('reserved.java', 13),\n",
       " ('use', 13),\n",
       " ('c', 13),\n",
       " ('return', 13),\n",
       " ('basics©', 12),\n",
       " ('c/c++', 12),\n",
       " ('may', 12),\n",
       " ('memory', 12),\n",
       " ('garbage', 11),\n",
       " ('basicsjava', 11),\n",
       " ('browser', 11),\n",
       " ('void', 11),\n",
       " ('primitive', 11),\n",
       " ('types', 11),\n",
       " ('allocate', 11),\n",
       " ('applets', 10),\n",
       " ('program', 10),\n",
       " ('following', 10),\n",
       " ('applications', 9),\n",
       " ('comments', 9),\n",
       " ('make', 9),\n",
       " ('file', 9),\n",
       " ('0', 9),\n",
       " ('reference', 9),\n",
       " ('operator', 9),\n",
       " ('null', 9),\n",
       " ('programs', 8),\n",
       " ('system', 8),\n",
       " ('two', 8),\n",
       " ('methods', 8),\n",
       " ('init', 8),\n",
       " ('stack', 8),\n",
       " ('would', 8),\n",
       " ('a.data', 8),\n",
       " ('one', 7),\n",
       " ('runtime', 7),\n",
       " ('g', 7),\n",
       " ('ok', 7),\n",
       " ('2', 7),\n",
       " ('pointers', 7),\n",
       " ('j', 7),\n",
       " ('b.data', 7),\n",
       " ('collection', 6),\n",
       " ('byte', 6),\n",
       " ('called', 6),\n",
       " ('args', 6),\n",
       " ('refer', 6),\n",
       " ('sizeof', 6),\n",
       " ('4', 6),\n",
       " ('arrays', 6),\n",
       " ('e', 6),\n",
       " ('f', 6)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordMoreThan5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
